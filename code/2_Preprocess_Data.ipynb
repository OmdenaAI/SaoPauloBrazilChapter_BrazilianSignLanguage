{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import json\n",
    "import gc\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess.video_analyzer import VideoAnalyzer, analyze_none_landmarks\n",
    "from preprocess.preprocessor import Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = \"04242025\"\n",
    "motion_version = \"versionB\"\n",
    "pose_version = \"versionB\"\n",
    "preprocessing_version = \"v4\"\n",
    "path_to_root = \"/home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(os.path.join(\n",
    "    path_to_root,\n",
    "    \"data\",\n",
    "    \"raw\",\n",
    "    \"combined\",\n",
    "    \"target_dataset_video_metadata.csv\"\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, metadata_row in metadata[:].iterrows():\n",
    "    print(f\"\\rProcessing video {i+1} of {len(metadata)}: {metadata_row.filename}\", end=\"\")\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "    analyzer = VideoAnalyzer(\n",
    "        metadata_row,\n",
    "        timestamp,\n",
    "        path_to_root,\n",
    "        verbose=False,\n",
    "        motion_detection_version=motion_version,\n",
    "        pose_detection_version=pose_version\n",
    "    )\n",
    "    pose_data = analyzer.pose_detect()\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "    pose_result = analyzer.pose_analyze()\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'\n",
    "\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'\n",
    "    motion_data = analyzer.motion_detect()\n",
    "    motion_result = analyzer.motion_analyze()\n",
    "\n",
    "    analyzer.save_analysis_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "289628344672473d8bd53047e80a6c73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, metadata_row in tqdm(metadata[:].iterrows(), total=len(metadata)):\n",
    "    gc.collect()\n",
    "    \n",
    "    with open(os.path.join(\n",
    "        path_to_root, \n",
    "        \"data\", \n",
    "        \"interim\", \n",
    "        \"Analysis\",\n",
    "        f\"{timestamp}_motion{motion_version}_pose{pose_version}\", \n",
    "        metadata_row[\"filename\"].split(\".\")[0] + \"_analysis_info.json\"\n",
    "        )) as f:\n",
    "        analysis_info = json.load(f)\n",
    "    \n",
    "    preprocessing_params = {\n",
    "        \"face_width_aim\": 0.155,\n",
    "        \"shoulders_width_aim\": 0.35,\n",
    "        \"face_midpoint_to_shoulders_height_aim\": 0.275,\n",
    "        \"shoulders_y_aim\": 0.52,\n",
    "        \"use_statistic\": \"mean\",\n",
    "        \"use_stationary_frames\": True,\n",
    "        \"skip_stationary_frames\": False,\n",
    "        \"start_frame\": analysis_info['motion_analysis']['start_frame'],\n",
    "        \"end_frame\": analysis_info['motion_analysis']['end_frame'],\n",
    "    }\n",
    "\n",
    "    preprocessor = Preprocessor(\n",
    "            metadata_row,\n",
    "            preprocessing_params,\n",
    "            path_to_root,\n",
    "            preprocess_version=preprocessing_version,\n",
    "            verbose=False,\n",
    "            save_intermediate=True,\n",
    "        )\n",
    "\n",
    "    preprocessor.preprocess_landmarks()\n",
    "    # preprocessor.preprocess_video()\n",
    "    \n",
    "\n",
    "        \n",
    "    # Force garbage collection after each video\n",
    "    gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
