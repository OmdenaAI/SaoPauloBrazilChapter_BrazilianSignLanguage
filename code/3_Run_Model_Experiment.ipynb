{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "drive_folder = 'Omdena LIBRAS SLP'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colab Env Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clone repo code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/OmdenaAI/SaoPauloBrazilChapter_BrazilianSignLanguage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mount your Google Drive folder that has the necessary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(f'/content/drive/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(f'drive/MyDrive/{drive_folder}/Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(f'drive/MyDrive/{drive_folder}/Data/preprocessed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(f'drive/MyDrive/{drive_folder}/Data/preprocessed/landmarks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy the data to the Colab environment repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/landmarks/v4']\n"
     ]
    }
   ],
   "source": [
    "data_version = 'v4'\n",
    "\n",
    "required_files = [\n",
    "]\n",
    "\n",
    "required_folders = [\n",
    "    f'/landmarks/{data_version}',\n",
    "]\n",
    "\n",
    "print(required_files + required_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "source_preprocessed_dir = f'drive/MyDrive/{drive_folder}/Data/preprocessed'\n",
    "target_preprocessed_dir = 'SaoPauloBrazilChapter_BrazilianSignLanguage/data/preprocessed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for required_file in required_files:\n",
    "  source = f'{source_preprocessed_dir}/{required_file}'\n",
    "  target = f'{target_preprocessed_dir}/{required_file}'\n",
    "  print(f'Copying file {required_file}')\n",
    "  print(f'\\tFrom: {source}')\n",
    "  print(f'\\tTo: {target}')\n",
    "  shutil.copy(source, target, dirs_exist_ok=True)\n",
    "  print('Copied')\n",
    "\n",
    "for required_folder in required_folders:\n",
    "  source = f'{source_preprocessed_dir}/{required_folder}'\n",
    "  target = f'{target_preprocessed_dir}/{required_folder}'\n",
    "  print(f'Copying folder {required_folder}')\n",
    "  print(f'\\tFrom: {source}')\n",
    "  print(f'\\tTo: {target}')\n",
    "  shutil.copytree(source, target, dirs_exist_ok=True)\n",
    "  print('Copied')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/code'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current working directory should be the root directory of the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "on_colab = True\n",
    "if on_colab:\n",
    "  # move down one directory\n",
    "  os.chdir('SaoPauloBrazilChapter_BrazilianSignLanguage')\n",
    "else:\n",
    "  # move up one directory\n",
    "  os.chdir('..')\n",
    "  \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the python environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Colab Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r colab_requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local Env\n",
    "If you are working locally, you should already create & activate a virtual environment, so that this notebook can run inside it.\n",
    "\n",
    "If you haven't already created the virtual environment, you can do so with the following command:\n",
    "\n",
    "`uv sync --extra model`\n",
    "\n",
    "Then activate the virtual environment with the following command:\n",
    "\n",
    "`source .venv/bin/activate` (On Linux/Mac)\\\n",
    "`venv\\Scripts\\activate` (On Windows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the python path to find our code modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTHONPATH'] = os.environ.get('PYTHONPATH', '') + ':' + os.path.join(os.getcwd(), 'code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":/home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/code\n"
     ]
    }
   ],
   "source": [
    "print(os.environ['PYTHONPATH'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the experiment settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Config Directory should be in the cloned repo, so shouldn't need to be changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dir =  os.path.join(os.getcwd(), 'code','model', 'configs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Training Run Directory should be located here, unless you want to save experiment logs elsewhere.\n",
    "The `drive_folder` is set at the beginning of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dir = f\"../drive/MyDrive/{drive_folder}/Data/runs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resume Previous Training Run\n",
    "\n",
    "If you are starting a new training run:\n",
    "- leave the `resume_training` flag as `False` and skip this section.\n",
    "\n",
    "If you are resuming a previous training run:\n",
    "- Set the training flag to `True`, and write the name of the run folder name\n",
    "- All the previous config settings will be used (loaded from the specified directory), so you can skip the `'Edit Configurations'` section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the resume training flag\n",
    "resume_training = False\n",
    "# set the run name\n",
    "run_name = \"12345678_654321_LSTM\"\n",
    "\n",
    "# check the run dir is accessible\n",
    "check_path = os.path.join(run_dir, run_name)\n",
    "# check the config file is accessible\n",
    "if os.path.isdir(check_path):\n",
    "    print(f'Run dir exists: {check_path}')\n",
    "else:\n",
    "    print(f'Run dir does not exist: {check_path}')\n",
    "    if os.path.isdir(run_dir):\n",
    "        print(f'Can\\'t find run dir in: {run_dir}')\n",
    "    else:\n",
    "        print(f'Can\\'t find main run dir: {run_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm the config before and after editing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Before edit--\n",
      "{'device': 'cuda',\n",
      " 'k_folds': 5,\n",
      " 'lr': '1e-4',\n",
      " 'num_epochs': 1,\n",
      " 'patience': 50,\n",
      " 'resume': False,\n",
      " 'run_dir': None,\n",
      " 'train_batch_size': 64,\n",
      " 'type': 'cross_validation',\n",
      " 'val_batch_size': 256}\n",
      "\n",
      "--After edit--\n",
      "{'device': 'cuda',\n",
      " 'k_folds': 5,\n",
      " 'lr': '1e-4',\n",
      " 'num_epochs': 1,\n",
      " 'patience': 50,\n",
      " 'resume': False,\n",
      " 'run_dir': None,\n",
      " 'train_batch_size': 64,\n",
      " 'type': 'cross_validation',\n",
      " 'val_batch_size': 256}\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(os.getcwd(), 'code','model', 'configs', 'training', 'training.yaml')\n",
    "with open(path, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "print('--Before edit--')\n",
    "pprint(config)\n",
    "\n",
    "config['resume'] = resume_training\n",
    "config['run_dir'] = os.path.join(run_dir, run_name)\n",
    "\n",
    "print('\\n--After edit--')\n",
    "pprint(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overwrite with the edited config:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path, \"w\") as f:\n",
    "    yaml.safe_dump(config, f, sort_keys=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edit Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many different configurations that can be set for the training process, model parameters, feature engineering, etc.\n",
    "\n",
    "The config yaml files are located in the `config` directory and be edited directly.\n",
    "\n",
    "For convenience, the cells below can be used to edit some of the key configuration settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the key configuration settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train config\n",
    "model = 'RNN'\n",
    "features = [\n",
    "    'positions',\n",
    "    'angles',\n",
    "    'differences',\n",
    "    'distances',\n",
    "    'metadata',\n",
    "    ]\n",
    "\n",
    "# training\n",
    "device = 'cpu'\n",
    "\n",
    "# dataset\n",
    "logs_base = run_dir\n",
    "\n",
    "# augmentation\n",
    "p_rotate = 0.5\n",
    "p_noise = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edit config files with the above settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train config\n",
    "path = os.path.join(config_dir, 'train_config.yaml')\n",
    "with open(path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "    \n",
    "config['defaults'][3]['model'] = model.lower()\n",
    "config['defaults'][6]['features'] = features\n",
    "\n",
    "pprint(config)\n",
    "with open(path, 'w') as f:\n",
    "    yaml.safe_dump(config, f, sort_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "path = os.path.join(config_dir, 'training/training.yaml')\n",
    "with open(path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "    \n",
    "config['device'] = device\n",
    "\n",
    "pprint(config)\n",
    "with open(path, 'w') as f:\n",
    "    yaml.safe_dump(config, f, sort_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "path = os.path.join(config_dir, 'dataset/dataset.yaml')\n",
    "with open(path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "config['logs_base'] = logs_base\n",
    "\n",
    "pprint(config)\n",
    "with open(path, 'w') as f:\n",
    "    yaml.safe_dump(config, f, sort_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentation\n",
    "path = os.path.join(config_dir, 'augmentation/base_augs.yaml')\n",
    "with open(path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "config['train']['rotate']['p'] = p_rotate\n",
    "config['train']['noise']['p'] = p_noise\n",
    "\n",
    "pprint(config)\n",
    "with open(path, 'w') as f:\n",
    "    yaml.safe_dump(config, f, sort_keys=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Optional] Monitor the training progress live with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The magic command below works on Colab or Jupyter Notebook.\\\n",
    "In VSCode, you can use the command palette to open the TensorBoard extension: `>Python: Launch TensorBoard`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../drive/MyDrive/Omdena LIBRAS SLP/Data/runs\n"
     ]
    }
   ],
   "source": [
    "print(run_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the path printed above to see all runs, or add the `run_name` to see a specific run. Using a specific run works better when resuming, as the folder called `run_name` won't exist yet otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir \"../drive/MyDrive/Omdena LIBRAS SLP/Data/runs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the training\n",
    "\n",
    "- The process will run for the `num_epochs` specified in the `training.yaml` file.\n",
    "- If early stopping is enabled, it will stop when the validation loss stops improving with the `patience` parameter specified.\n",
    "- The training settings & logs will be saved to the `run_dir` directory.\n",
    "- You can monitor the training progress live with TensorBoard.\n",
    "- If the process is interrupted, it can be resumed by setting the `resume_training` flag to `True` and using the same `run_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python code/model/trainer.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
