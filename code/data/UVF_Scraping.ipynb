{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to scrape and list all the categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alimentos\n",
      "Animais e Insetos\n",
      "Comemorações\n",
      "Comunicação e Eletrônicos\n",
      "Construção\n",
      "Cores\n",
      "Corpo Humano\n",
      "Cumprimentos\n",
      "Dinheiro\n",
      "Disciplina\n",
      "Escola\n",
      "Esporte e Diversão\n",
      "Instrumentos Musicais\n",
      "Lugares, Cidades e Países\n",
      "Meios de Transporte\n",
      "Natureza\n",
      "Números\n",
      "Objetos\n",
      "Pessoas e Família\n",
      "Profissões\n",
      "Situações, Cotidiano e Eventos\n",
      "Tempo e Calendário\n",
      "Verbos\n",
      "Vestuário\n",
      "Acessar histórico\n",
      "Biologia\n",
      "Letras\n",
      "Matemática\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Base URL of the dictionary page\n",
    "base_url = \"https://sistemas.cead.ufv.br/capes/dicionario/\"\n",
    "\n",
    "# Set up Chrome WebDriver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option(\"detach\", True)  # Keeps the browser open after script ends\n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.get(base_url)  # Open the dictionary website\n",
    "\n",
    "# WebDriver wait object (max 15 seconds for elements to appear)\n",
    "wait = WebDriverWait(driver, 15)\n",
    "\n",
    "# Get all category links\n",
    "category_elements = wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \".categories a\")))\n",
    "\n",
    "# Iterate over categories and print their names\n",
    "for category in category_elements:\n",
    "    print(category.text.strip())  # Print category name\n",
    "\n",
    "# Close browser when done\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to scrape and list all the words in one of the categories. In this example all the words from the first category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing words: ['Abacate', 'Abacaxi', 'Abóbora', 'Açaí', 'Acerola', 'Achocolatado', 'Açúcar', 'Água de coco', 'Alface', 'Alho', 'Amendoim', 'Amora', 'Arroz', 'Azeite']\n",
      "Processing words: ['Azeitona', 'Bacon', 'Bala', 'Banana', 'Banquete', 'Batata', 'Batata Frita', 'Batida (Bebida)', 'Berinjela', 'Bife', 'Biscoito água e sal', 'Bolacha', 'Bolo', 'Bombom']\n",
      "Processing words: ['Brócolis', 'Café', 'Caju', 'Camarão', 'Caqui', 'Carne', 'Cebola', 'Cebolinha', 'Cereja', 'Cerveja', 'Chocolate', 'Churrasco', 'Coca Cola', 'Coco']\n",
      "Processing words: ['Cogumelo', 'Comida', 'Couve', 'Coxinha', 'Damasco', 'Doce', 'Doce de abóbora', 'Empada', 'Ervilha', 'Espinafre', 'Farinha', 'Farofa', 'Feijão', 'Feijoada']\n",
      "Processing words: ['Fermento', 'Figo', 'Goiabada', 'Jabuticaba', 'Laranja (Fruta)', 'Massa', 'Melancia', 'Pêra', 'Picolé', 'Sopa', 'Sorvete', 'Tomate', 'Torrada', 'Uva']\n",
      "Processing words: ['Vagem', 'Vinho (bebida)', 'Vitamina', 'Vitamina (bebida)']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Open Chrome WebDriver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option(\"detach\", True)  # Keep browser open\n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.get(\"https://sistemas.cead.ufv.br/capes/dicionario/\")  # Open dictionary site\n",
    "\n",
    "# Wait object (max 15 sec)\n",
    "wait = WebDriverWait(driver, 15)\n",
    "\n",
    "# Get all category elements\n",
    "category_elements = wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \".categories a\")))\n",
    "\n",
    "# Highlight first category for manual selection\n",
    "driver.execute_script(\"arguments[0].style.border='3px solid red'\", category_elements[0])\n",
    "\n",
    "# Ask user to manually select a category\n",
    "input(\"Click the highlighted category in the browser, then press Enter to continue...\")\n",
    "\n",
    "# Dictionary to store metadata\n",
    "word_metadata = {}\n",
    "\n",
    "words_list = []  # Store words in order\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        # Extract words from the current carousel page\n",
    "        word_elements = wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \".carousel-inner .item.active a\")))\n",
    "\n",
    "        current_page_words = []\n",
    "\n",
    "        for word in word_elements:\n",
    "            word_text = word.text.strip()\n",
    "\n",
    "            # Skip empty words\n",
    "            if word_text == \"\":\n",
    "                continue  \n",
    "\n",
    "            current_page_words.append(word_text)\n",
    "\n",
    "        # Check if the same sequence of words has already appeared\n",
    "        if any(word in words_list for word in current_page_words):\n",
    "            break  # Stop if carousel repeats\n",
    "\n",
    "        # Add new words to the overall list\n",
    "        words_list.extend(current_page_words)\n",
    "\n",
    "        print(\"Processing words:\", current_page_words)\n",
    "\n",
    "        # Extract metadata for each word in the current page\n",
    "        for word in current_page_words:\n",
    "            word_element = driver.find_element(By.LINK_TEXT, word)\n",
    "            word_url = word_element.get_attribute(\"href\")\n",
    "\n",
    "            #time.sleep(2)\n",
    "\n",
    "            # Open word page\n",
    "            #driver.get(word_url)\n",
    "\n",
    "            # Extract Example in Portuguese\n",
    "            try:\n",
    "                example_pt = wait.until(EC.presence_of_element_located(\n",
    "                    (By.XPATH, \"//h3[contains(text(),'Exemplo em português')]/following-sibling::h4\"))).text.strip()\n",
    "            except:\n",
    "                example_pt = \"Not Available\"\n",
    "\n",
    "            # Extract Example in Libras\n",
    "            try:\n",
    "                example_libras = wait.until(EC.presence_of_element_located(\n",
    "                    (By.XPATH, \"//h3[contains(text(),'Exemplo em libras')]/following-sibling::h4\"))).text.strip()\n",
    "            except:\n",
    "                example_libras = \"Not Available\"\n",
    "\n",
    "            # Extract Video URL\n",
    "            try:\n",
    "                video_element = wait.until(EC.presence_of_element_located((By.TAG_NAME, \"video\")))\n",
    "                video_url = video_element.get_attribute(\"src\")\n",
    "            except:\n",
    "                video_url = \"Not Available\"\n",
    "\n",
    "            # Store metadata in dictionary\n",
    "            word_metadata[word] = {\n",
    "                \"example_pt\": example_pt,\n",
    "                \"example_libras\": example_libras,\n",
    "                \"video_url\": video_url\n",
    "            }\n",
    "\n",
    "\n",
    "        # Click \"Next\" button to load more words\n",
    "        next_button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \".right[role='button']\")))\n",
    "        next_button.click()\n",
    "        time.sleep(10)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error or no more words:\", e)\n",
    "        break  # Stop if any issue occurs\n",
    "\n",
    "#print(\"\\nFinal Word Metadata Dictionary:\\n\", word_metadata)\n",
    "import pandas as pd\n",
    "\n",
    "# Convert dictionary to DataFrame\n",
    "df = pd.DataFrame.from_dict(word_metadata, orient='index')\n",
    "\n",
    "# Save DataFrame to CSV\n",
    "df.to_csv(\"Dicionario_Metadata.csv\", encoding=\"utf-8\", index_label=\"Word\")\n",
    "\n",
    "# Close browser\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to extract all the metadata for all the words in one category. The metadata is first stored as a dictionary and then saved in a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing words: ['Abacate', 'Abacaxi', 'Abóbora', 'Açaí', 'Acerola', 'Achocolatado', 'Açúcar', 'Água de coco', 'Alface', 'Alho', 'Amendoim', 'Amora', 'Arroz', 'Azeite']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Open Chrome WebDriver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option(\"detach\", True)  # Keep browser open\n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.get(\"https://sistemas.cead.ufv.br/capes/dicionario/\")  # Open dictionary site\n",
    "\n",
    "# Wait object (max 15 sec)\n",
    "wait = WebDriverWait(driver, 15)\n",
    "\n",
    "# Get all category elements\n",
    "category_elements = wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \".categories a\")))\n",
    "\n",
    "# Highlight first category for manual selection\n",
    "driver.execute_script(\"arguments[0].style.border='3px solid red'\", category_elements[0])\n",
    "\n",
    "# Ask user to manually select a category\n",
    "input(\"Click the highlighted category in the browser, then press Enter to continue...\")\n",
    "\n",
    "# Dictionary to store metadata\n",
    "word_metadata = {}\n",
    "\n",
    "words_list = []  # Store words in order\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        # Extract words from the current carousel page\n",
    "        word_elements = wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \".carousel-inner .item.active a\")))\n",
    "\n",
    "        current_page_words = []\n",
    "\n",
    "        for word in word_elements:\n",
    "            word_text = word.text.strip()\n",
    "\n",
    "            # Skip empty words\n",
    "            if word_text == \"\":\n",
    "                continue  \n",
    "\n",
    "            current_page_words.append(word_text)\n",
    "\n",
    "        # Check if the same sequence of words has already appeared (prevents looping)\n",
    "        if any(word in words_list for word in current_page_words):\n",
    "            break  # Stop if carousel repeats\n",
    "\n",
    "        # Add new words to the overall list\n",
    "        words_list.extend(current_page_words)\n",
    "\n",
    "        print(\"Processing words:\", current_page_words)\n",
    "\n",
    "        # Extract metadata for each word in the current page\n",
    "        for word in current_page_words:\n",
    "            try:\n",
    "                word_element = driver.find_element(By.LINK_TEXT, word)\n",
    "                word_url = word_element.get_attribute(\"href\")\n",
    "\n",
    "                # Open word page\n",
    "                driver.get(word_url)\n",
    "\n",
    "                # Extract Example in Portuguese\n",
    "                try:\n",
    "                    example_pt = wait.until(EC.presence_of_element_located(\n",
    "                        (By.XPATH, \"//h3[contains(text(),'Exemplo em português')]/following-sibling::h4\"))).text.strip()\n",
    "                except:\n",
    "                    example_pt = \"Not Available\"\n",
    "\n",
    "                # Extract Example in Libras\n",
    "                try:\n",
    "                    example_libras = wait.until(EC.presence_of_element_located(\n",
    "                        (By.XPATH, \"//h3[contains(text(),'Exemplo em libras')]/following-sibling::h4\"))).text.strip()\n",
    "                except:\n",
    "                    example_libras = \"Not Available\"\n",
    "\n",
    "                # Extract Video URL\n",
    "                try:\n",
    "                    video_element = wait.until(EC.presence_of_element_located((By.TAG_NAME, \"video\")))\n",
    "                    video_url = video_element.get_attribute(\"src\")\n",
    "                except:\n",
    "                    video_url = \"Not Available\"\n",
    "\n",
    "                # Store metadata in dictionary\n",
    "                word_metadata[word] = {\n",
    "                    \"example_pt\": example_pt,\n",
    "                    \"example_libras\": example_libras,\n",
    "                    \"video_url\": video_url\n",
    "                }\n",
    "\n",
    "                # Go back to category page\n",
    "                #driver.back()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping word '{word}' due to error:\", e)\n",
    "                continue\n",
    "\n",
    "        # Click \"Next\" button to load more words\n",
    "        next_button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \".right[role='button']\")))\n",
    "        next_button.click()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error or no more words:\", e)\n",
    "        break  # Stop if any issue occurs\n",
    "\n",
    "# Convert dictionary to DataFrame\n",
    "df = pd.DataFrame.from_dict(word_metadata, orient='index')\n",
    "\n",
    "# Save DataFrame to CSV\n",
    "df.to_csv(\"Dicionario_Metadata.csv\", encoding=\"utf-8\", index_label=\"Word\")\n",
    "\n",
    "# Close browser\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
