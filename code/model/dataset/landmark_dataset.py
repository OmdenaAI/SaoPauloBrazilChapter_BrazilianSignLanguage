from torch.utils.data import Dataset
import pandas as pd
import numpy as np
import torch
from model.utils.utils import load_config, load_obj
from typing import Dict, List, Union, Callable, Tuple
from model.utils.path_utils import get_data_paths
from functools import partial
import os
from omegaconf import DictConfig
import os
from . import frame_sampling
from model.features.feature_processor import FeatureProcessor
import time
from omegaconf import OmegaConf

def uniform_intervals(start: int, end: int, interval: int):
    return list(range(start, end + 1, interval))


def random_timestamps(start: int, end: int, interval: int):
    return sorted(np.random.randint(start, end + 1, size=interval).tolist())


def uniform_timestamps(start: int, end: int, interval: int) -> List[int]:
    return list(np.linspace(start, end, num=interval, dtype=int))


INTERVAL_FUNCTIONS = {
    "uniform_intervals": uniform_intervals,
    "random_timestamps": random_timestamps,
    "uniform_timestamps": uniform_timestamps,
}


def select_frame_indices_by_time_interval(
    timestamps_ms: List[int], 
    interval_fn: Callable[[int, int], List[int]],
    min_frames_between_samples: int = None
) -> List[int]:
    """
    Selects frame indices based on desired timestamps generated by `interval_fn`.

    Parameters:
    -----------
    timestamps_ms : List[int]
        Sorted list of frame timestamps in milliseconds.
    interval_fn : Callable
        A function that takes (start_time, end_time) and returns a list of desired timestamps (ms).
    min_frames_between_samples : int, optional
        Minimum number of frames required between samples. Used to validate sampling.

    Returns:
    --------
    List[int] : Indices of frames closest to the desired timestamps.
    """
    timestamps = np.array(timestamps_ms)
    start_time, end_time = timestamps[0], timestamps[-1]
    target_times = interval_fn(int(start_time), int(end_time))

    selected_indices = []
    for target in target_times:
        closest_idx = np.argmin(np.abs(timestamps - target))
        
        # Check if this index maintains minimum frame separation
        if min_frames_between_samples is not None and selected_indices:
            if closest_idx - selected_indices[-1] < min_frames_between_samples:
                continue
                
        if not selected_indices or closest_idx != selected_indices[-1]:  # avoid duplicates
            selected_indices.append(closest_idx)

    return selected_indices


class LandmarkFeatureTorchJoiner:
    def forward(self, landmark_features: Dict):
        feature_vector = []
        for landmark_type in landmark_features.keys():
            feature_vector.extend(landmark_features[landmark_type])
        return torch.tensor(feature_vector, dtype=torch.float)


class LandmarkDataset(Dataset):
    def __init__(
        self,
        dataset_config: Union[str, Dict, DictConfig],
        features_config: Union[str, Dict, DictConfig],
        augmentation_config: Union[str, Dict, DictConfig],
        dataset_split: str,
        seed: int = None,
    ):
        # these configs should already be DictConfig objects, load_config is just for safety
        self.dataset_config = load_config(dataset_config, "dataset_config")
        self.features_config = load_config(features_config, "features_config")
        self.augmentation_config = load_config(augmentation_config, "augmentation_config")
        self.dataset_split = dataset_split
        self.seed = seed

        # Get standardized paths based on data version
        self.data_dir, metadata_path = get_data_paths(self.dataset_config["data_version"])
        
        # Load and filter metadata
        self.metadata = pd.read_csv(metadata_path)
        self.metadata = self.metadata[self.metadata["dataset_split"] == dataset_split]
        
        # Frame sampling configuration
        if self.dataset_split == "train":
            sampling_config = self.dataset_config["frame_sampling_train"]
            self.sampling_func = frame_sampling.get_sampling_function(sampling_config["method"])
            self.sampling_params = sampling_config["params"].copy()  # Create a copy to avoid modifying the original
        else:
            # Use test sampling for validation and test splits
            sampling_config = self.dataset_config["frame_sampling_test"]
            self.sampling_func = frame_sampling.get_sampling_function(sampling_config["method"])
            self.sampling_params = sampling_config["params"].copy()  # Create a copy to avoid modifying the original

        # Add seed to sampling parameters if provided
        if seed is not None:
            self.sampling_params["seed"] = seed

        # Calculate samples per video and store all samples
        self.samples_per_video = []
        self.all_samples = []  # Store all samples for each video
        for idx in range(len(self.metadata)):
            frames = self._load_frames(idx)
            samples = self.sampling_func(
                num_frames=len(frames),
                params=self.sampling_params
            )
            self.samples_per_video.append(len(samples))
            self.all_samples.append(samples)  # Store the samples
            
        # Cumulative sum for index mapping
        self.cumsum_samples = np.cumsum([0] + self.samples_per_video)

        # Initialize feature processor
        self.feature_processor = FeatureProcessor(
            dataset_split=self.dataset_split,
            dataset_config=self.dataset_config,
            features_config=self.features_config,
            augmentation_config=self.augmentation_config,
            landmarks_dir=self.data_dir,
        )

    def _load_frames(self, idx: int):
        """Helper to load frames for a video."""
        idx = self.metadata.index[idx]
        landmark_path = os.path.join(self.data_dir, self.metadata.loc[idx, "filename"])
        frames = np.load(landmark_path, allow_pickle=True)
        return frames

    def __len__(self) -> int:
        return self.cumsum_samples[-1]

    def _check_landmark_config(
        self, first_key: str, second_key: str
    ) -> Tuple[str, str]:
        """To allow free order of of features inside a feature vectors"""
        if second_key in self.configuration["landmark_types"]:
            return first_key, second_key
        if first_key in self.configuration["landmark_types"]:
            return second_key, first_key

        raise Exception(
            "Error with landmark_features in dataset config, it is not specified correctly"
        )

    def __getitem__(self, idx: int):
        get_item_timing = {
            'index_calculation': 0.0,
            'frame_loading': 0.0,
            'sample_selection': 0.0,
            'metadata_lookup': 0.0,
            'feature_processing': 0.0,
            'label_creation': 0.0,
        }
        ic_start_time = time.time()
        # Find which video this index belongs to
        ## idx_position is the raw index, and can be used with df.iloc to get the ith row
        ## idx_number is the row's actual number in the index column of the df
        ## the self.metadata df is a subset of the full metadata df, but still retains the original index numbers
        ## so the index used for df.iloc and df.loc usually differ
        video_idx_position = np.searchsorted(self.cumsum_samples, idx, side='right') - 1
        video_idx_number = self.metadata.index[video_idx_position]
        # Calculate which sample number this is for this video
        sample_idx = idx - self.cumsum_samples[video_idx_position]
        get_item_timing['index_calculation'] = time.time() - ic_start_time
        
        # Load the frames
        fl_start_time = time.time()
        frames = self._load_frames(video_idx_position)
        get_item_timing['frame_loading'] = time.time() - fl_start_time
        
        # Get the pre-calculated sample for this index
        ss_start_time = time.time()
        selected_indices = self.all_samples[video_idx_position][sample_idx]
        get_item_timing['sample_selection'] = time.time() - ss_start_time

        # Get the metadata row
        ml_start_time = time.time()
        metadata_row = self.metadata.iloc[video_idx_position]
        get_item_timing['metadata_lookup'] = time.time() - ml_start_time

        # Process frames using feature processor
        fp_start_time = time.time()
        features = self.feature_processor.process_frames(frames, selected_indices, metadata_row, self.dataset_split)
        get_item_timing['feature_processing'] = time.time() - fp_start_time

        # Get label
        lc_start_time = time.time()
        label = torch.tensor([self.metadata.loc[video_idx_number, "label_encoded"]], dtype=torch.int64)
        get_item_timing['label_creation'] = time.time() - lc_start_time

        # When using a dataloader, we usually pass collate_func_pad to the dataloader
        # which will return a tuple of (features, labels, attention_mask), skipping the get_item_timing
        return features, label, get_item_timing

    def get_video_idx(self, idx: int) -> int:
        """
        Get the video index for a given sample index.
        
        Args:
            idx: Sample index
            
        Returns:
            Original video index from metadata
        """
        # Find which video this index belongs to
        video_idx_position = np.searchsorted(self.cumsum_samples, idx, side='right') - 1
        # Return the actual index number from metadata
        return self.metadata.index[video_idx_position]

    def get_samples_for_video(self, video_idx: int) -> List[int]:
        """
        Get all sample indices for a given video.
        
        Args:
            video_idx: Video index from metadata
            
        Returns:
            List of sample indices for this video
        """
        # Find position of video in metadata
        video_position = self.metadata.index.get_loc(video_idx)
        # Get start and end indices for this video's samples
        start_idx = self.cumsum_samples[video_position]
        end_idx = self.cumsum_samples[video_position + 1]
        return list(range(start_idx, end_idx))

    def save(self, save_path: str, epoch: int = None) -> None:
        """Save the dataset state to a file.
        
        Args:
            save_path: Path to save the dataset state to
        """
        # Create a dictionary of all the important state
        state = {
            'dataset_config': OmegaConf.to_container(self.dataset_config),
            'features_config': OmegaConf.to_container(self.features_config),
            'augmentation_config': OmegaConf.to_container(self.augmentation_config),
            'dataset_split': self.dataset_split,
            'seed': self.seed,
            'metadata': self.metadata,
            'samples_per_video': self.samples_per_video,
            'all_samples': self.all_samples,
            'cumsum_samples': self.cumsum_samples,
            'sampling_params': self.sampling_params,
            'sampling_func_name': self.sampling_func.__name__,
        }
        if epoch is not None:
            state['epoch'] = epoch
        
        # Save the state
        torch.save(state, save_path)
        print(f"Saved dataset state to: {save_path}")

    @classmethod
    def load(cls, load_path: str) -> 'LandmarkDataset':
        """Load a dataset state from a file.
        
        Args:
            load_path: Path to load the dataset state from
            
        Returns:
            A new LandmarkDataset instance with the loaded state
        """
        # Load the state
        state = torch.load(load_path)
        
        # Create a new dataset instance with the loaded configs
        dataset = cls(
            dataset_config=state['dataset_config'],
            features_config=state['features_config'],
            augmentation_config=state['augmentation_config'],
            dataset_split=state['dataset_split'],
            seed=state['seed']
        )
        
        # Restore the state
        dataset.metadata = state['metadata']
        dataset.samples_per_video = state['samples_per_video']
        dataset.all_samples = state['all_samples']
        dataset.cumsum_samples = state['cumsum_samples']
        dataset.sampling_params = state['sampling_params']
        
        # Restore the sampling function
        dataset.sampling_func = frame_sampling.get_sampling_function(state['sampling_func_name'])
        if 'epoch' in state:
            dataset.epoch = state['epoch']
        print(f"Loaded dataset state from: {load_path}")
        print(f"Epoch: {dataset.epoch}")

        return dataset
