from torch.utils.data import Dataset
import pandas as pd
import numpy as np
import torch
from models.landmark.utils import load_config
from typing import Dict, List, Union, Callable, Tuple
from models.landmark.dataset.angles_estimator import AnglesEstimator
from models.landmark.dataset.distances_estimator import DistancesEstimator
from models.landmark.dataset.frame2frame_differences_estimator import (
    DifferencesEstimator,
)
from models.landmark.dataset.augmentations import AUGMENTATIONS
from functools import partial
import os
from mediapipe.framework.formats import landmark_pb2


def uniform_intervals(start: int, end: int, interval: int):
    return list(range(start, end + 1, interval))


def random_timestamps(start: int, end: int, interval: int):
    return sorted(np.random.randint(start, end + 1, size=interval).tolist())


def uniform_timestamps(start: int, end: int, interval: int) -> List[int]:
    return list(np.linspace(start, end, num=interval, dtype=int))


INTERVAL_FUNCTIONS = {
    "uniform_intervals": uniform_intervals,
    "random_timestamps": random_timestamps,
    "uniform_timestamps": uniform_timestamps,
}


def select_frame_indices_by_time_interval(
    timestamps_ms: List[int], interval_fn: Callable[[int, int], List[int]]
) -> List[int]:
    """
    Selects frame indices based on desired timestamps generated by `interval_fn`.

    Parameters:
    -----------
    timestamps_ms : List[int]
        Sorted list of frame timestamps in milliseconds.

    interval_fn : Callable
        A function that takes (start_time, end_time) and returns a list of desired timestamps (ms).

    Returns:
    --------
    List[int] : Indices of frames closest to the desired timestamps.
    """
    timestamps = np.array(timestamps_ms)
    start_time, end_time = timestamps[0], timestamps[-1]
    target_times = interval_fn(int(start_time), int(end_time))

    selected_indices = []
    for target in target_times:
        closest_idx = np.argmin(np.abs(timestamps - target))
        if (
            not selected_indices or closest_idx != selected_indices[-1]
        ):  # avoid duplicates
            selected_indices.append(closest_idx)

    return selected_indices


class LandmarkFeatureTorchJoiner:
    def forward(self, landmark_features: Dict):
        feature_vector = []
        for landmark_type in landmark_features.keys():
            feature_vector.extend(landmark_features[landmark_type])
        return torch.tensor(feature_vector, dtype=torch.float)


class LandmarkDataset(Dataset):
    def __init__(self, config: Union[str, Dict], dataset_split: str):
        config = load_config(config, "dataset_config")
        self.data_dir = config["data_dir"]
        self.data = pd.read_csv(config["data_path"])
        self.data = self.data[self.data["dataset_split"] == dataset_split]
        self.augmentations = AUGMENTATIONS[dataset_split]
        self.landmark_features = config["landmark_features"]
        self.frame_interval_fn = partial(
            INTERVAL_FUNCTIONS[config["frame_interval_fn"]], interval=config["interval"]
        )
        self.feature_computation_types = config["feature_computation_types"]
        self.feature_modes = config["feature_modes"]

        self.estimators = {
            "angles": AnglesEstimator(
                hand_angles=config["hand_angle_triplets"],
                pose_angles=config["pose_angle_triplets"],
            ),
            "distances": DistancesEstimator(
                hand_distances=config["hand_distance_pairs"],
                pose_distances=config["pose_distance_pairs"],
            ),
            "differences": DifferencesEstimator(
                hand_differences=config["hand_differences"],
                pose_differences=config["pose_differences"],
            ),
        }
        self.landmark_types = config["landmark_types"]

    def __len__(self) -> int:
        return self.data.shape[0]

    def _check_landmark_config(
        self, first_key: str, second_key: str
    ) -> Tuple[str, str]:
        """To allow free order of of features inside a feature vectors"""

        if second_key in self.landmark_types:
            return first_key, second_key
        if first_key in self.landmark_types:
            return second_key, first_key

        raise Exception(
            "Error with landmark_features in dataset config, it is not specified correctly"
        )

    def _get_empty_landmark_list(self, landmark_type: str):
        landmark_numbers = {"right_hand": 21,
                            "left_hand": 21,
                            "pose": 33}
        return landmark_pb2.NormalizedLandmarkList(
            landmark=[
                landmark_pb2.NormalizedLandmark(x=0.0, y=0.0, z=0.0)
                for _ in range(landmark_numbers[landmark_type])
            ]
        )

    def __getitem__(self, idx: int):
        idx = self.data.index[idx]
        landmark_path = os.path.join(self.data_dir, self.data.loc[idx, "filename"])
        label = torch.tensor([self.data.loc[idx, "label_encoded"]], dtype=torch.int64)
        preprocessed_first_index = self.data.loc[idx, "preprocessed_start_frame"]
        preprocessed_last_index = self.data.loc[idx, "preprocessed_end_frame"]
        frames = np.load(landmark_path, allow_pickle=True)
        frames = frames[preprocessed_first_index:preprocessed_last_index]

        for i in range(len(frames)):
            for key in self.landmark_types:
                if frames[i][f"{key}_landmarks"] is None:
                    frames[i][f"{key}_landmarks"] = self._get_empty_landmark_list(
                        key        
                        )
                    
        # Get timestamps and select relevant frame indices
        timestamps = [f["timestamp_ms"] for f in frames]
        selected_indices = select_frame_indices_by_time_interval(
            timestamps, self.frame_interval_fn
        )

        # Compute features
        all_features = []
        for indx, i in enumerate(selected_indices):
            frame = frames[i]
            frame = {
                f"{key}_landmarks": frame[f"{key}_landmarks"].landmark
                for key in self.landmark_types
            }

            for aug in self.augmentations:
                if np.random.uniform() <= aug["p"]:
                    frame = aug["augmentation"](frame)
            features = {}

            if indx > 0:
                prev_frame = frames[selected_indices[indx - 1]]
                prev_frame = {
                    f"{key}_landmarks": prev_frame[f"{key}_landmarks"].landmark
                    for key in self.landmark_types
                }
            else:
                prev_frame = {
                    f"{key}_landmarks": self._get_empty_landmark_list(key).landmark
                    for key in self.landmark_types
                }

            for first_key in self.landmark_features:
                for second_key in self.landmark_features[first_key]:
                    feature_type, landmark_type = self._check_landmark_config(
                        first_key, second_key
                    )
                    if feature_type == "differences":
                        features[f"{feature_type}/{landmark_type}"] = (
                                self.estimators[feature_type].compute(
                                    prev_frame[f"{landmark_type}_landmarks"],
                                    frame[f"{landmark_type}_landmarks"],
                                    landmark_type=landmark_type.split("_")[-1],
                                    mode=self.feature_modes[feature_type],
                                    computation_type=self.feature_computation_types[
                                        feature_type
                                    ],
                                )
                            )
                    else:
                        features[f"{feature_type}/{landmark_type}"] = self.estimators[
                            feature_type
                        ].compute(
                            frame[f"{landmark_type}_landmarks"],
                            landmark_type=landmark_type.split("_")[-1],
                            mode=self.feature_modes[feature_type],
                            computation_type=self.feature_computation_types[
                                feature_type
                            ],
                        )
            feature_vector = np.concatenate(list(features.values()), axis=None)

            all_features.append(torch.tensor(feature_vector, dtype=torch.float))
            # print(len(all_features))
        if len(all_features) < 15:
            print(selected_indices, landmark_path)
        return torch.stack(all_features), label
