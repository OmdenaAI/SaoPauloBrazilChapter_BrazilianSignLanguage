from torch.utils.data import Dataset
import pandas as pd
import numpy as np
import torch
from models.landmark.utils import load_config
from typing import Dict, List, Union, Callable
from models.landmark.dataset.angles_estimator import AnglesEstimator
from models.landmark.dataset.distances_estimator import DistancesEstimator
from models.landmark.dataset.frame2frame_differences_estimator import (
    DifferencesEstimator,
)
from models.landmark.dataset.augmentations import AUGMENTATIONS
from functools import partial
import os


def uniform_intervals(start: int, end: int, interval: int):
    return list(range(start, end + 1, interval))


def random_timestamps(start: int, end: int, interval: int):
    return sorted(np.random.randint(start, end + 1, size=interval).tolist())


INTERVAL_FUNCTIONS = {
    "uniform_intervals": uniform_intervals,
    "random_timestamps": random_timestamps,
}


def select_frame_indices_by_time_interval(
    timestamps_ms: List[int], interval_fn: Callable[[int, int], List[int]]
) -> List[int]:
    """
    Selects frame indices based on desired timestamps generated by `interval_fn`.

    Parameters:
    -----------
    timestamps_ms : List[int]
        Sorted list of frame timestamps in milliseconds.

    interval_fn : Callable
        A function that takes (start_time, end_time) and returns a list of desired timestamps (ms).

    Returns:
    --------
    List[int] : Indices of frames closest to the desired timestamps.
    """
    timestamps = np.array(timestamps_ms)
    start_time, end_time = timestamps[0], timestamps[-1]
    target_times = interval_fn(int(start_time), int(end_time))

    selected_indices = []
    for target in target_times:
        closest_idx = np.argmin(np.abs(timestamps - target))
        if (
            not selected_indices or closest_idx != selected_indices[-1]
        ):  # avoid duplicates
            selected_indices.append(closest_idx)

    return selected_indices


class LandmarkFeatureTorchJoiner:
    def __init__(self, landmark_order: List[str]):
        self.landmark_order = landmark_order

    def forward(self, landmark_features: Dict):
        feature_vector = []
        for landmark_type in self.landmark_order:
            feature_vector.extend(landmark_features[landmark_type])
        return torch.tensor(feature_vector, dtype=torch.float)


class LandmarkDataset(Dataset):
    def __init__(self, config: Union[str, Dict],
                 dataset_split: str):
        config = load_config(config, "dataset_config")
        self.data_dir = config["data_dir"]
        self.data = pd.read_csv(config["data_path"])
        self.data = self.data[self.data["dataset_split"] == dataset_split]
        self.augmentations = AUGMENTATIONS[dataset_split]
        self.landmark_order = config["landmark_order"]
        self.landmark_feature_list = config["landmark_feature_list"]
        self.frame_interval_fn = partial(
            INTERVAL_FUNCTIONS[config["frame_interval_fn"]], interval=config["interval"]
        )
        self.distance_type = config["distance_type"]
        self.angle_type = config["angle_type"]
        self.diff_type = config["diff_type"]
        
        self.angle_mode = config["distance_mode"]
        self.distance_mode = config["distance_mode"]
        self.diff_mode = config["diff_mode"]

        self.angle_estimator = AnglesEstimator(
            hand_angles=config["hand_angle_triplets"],
            pose_angles=config["pose_angle_triplets"]
        )
        self.distance_estimator = DistancesEstimator(
            hand_distances=config["hand_distance_pairs"],
            pose_distances=config["pose_distance_pairs"]
        )
        self.diff_estimator = DifferencesEstimator(
            hand_differences=config["hand_differences"],
            pose_differences=config["pose_differences"]
        )

        self.joiner = LandmarkFeatureTorchJoiner(self.landmark_feature_list)

    def __len__(self) -> int:
        return self.data.shape[0]

    def __getitem__(self, idx: int):
        landmark_path = os.path.join(self.data_dir, self.data.loc[idx, "filename"])
        frames = np.load(landmark_path, allow_pickle=True)

        # Get timestamps and select relevant frame indices
        timestamps = [f["timestamp_ms"] for f in frames]
        selected_indices = select_frame_indices_by_time_interval(
            timestamps, self.frame_interval_fn
        )

        # Compute features
        all_features = []
        for indx, i in enumerate(selected_indices):
            frame = frames[i]
            frame = {key: value.landmark for key, value in frame.items()}

            for aug in self.augmentations:
                if np.random.uniform() <= aug["p"]:
                    frame = aug["augmentation"](frame)
            features = {}

            if "angles" in self.landmark_feature_list:
                features["angles"] = []
                if frame["pose_landmarks"]:
                    features["angles"] += self.angle_estimator.compute_angles(
                        frame["pose_landmarks"], "pose", 
                        mode=self.angle_mode,
                        angle_type=self.angle_type
                    )
                if frame["left_hand_landmarks"]:
                    features["angles"] += self.angle_estimator.compute_angles(
                        frame["left_hand_landmarks"], "hand", 
                        mode=self.angle_mode,
                        angle_type=self.angle_type
                    )
                if frame["right_hand_landmarks"]:
                    features["angles"] += self.angle_estimator.compute_angles(
                        frame["right_hand_landmarks"],
                        "hand",
                        mode=self.angle_mode,
                        angle_type=self.angle_type,
                    )

            if "distances" in self.landmark_feature_list:
                features["distances"] = []
                if frame["pose_landmarks"]:
                    features["distances"] += self.distance_estimator.compute_distances(
                        frame["pose_landmarks"],
                        "pose",
                        mode=self.distance_mode,
                        distance_type=self.distance_type,
                    )
                if frame["left_hand_landmarks"]:
                    features["distances"] += self.distance_estimator.compute_distances(
                        frame["left_hand_landmarks"],
                        "hand",
                        mode=self.distance_mode,
                        distance_type=self.distance_type,
                    )
                if frame["right_hand_landmarks"]:
                    features["distances"] += self.distance_estimator.compute_distances(
                        frame["right_hand_landmarks"],
                        "hand",
                        mode=self.distance_mode,
                        distance_type=self.distance_type,
                    )

            if "differences" in self.landmark_feature_list and indx > 0:
                prev_frame = frames[selected_indices[indx - 1]]
                prev_frame = {key: value.landmark for key, value in prev_frame.items()}
                features["differences"] = []
                if frame["pose_landmarks"]:
                    features["differences"] += (
                        self.diff_estimator.compute_differences(
                            prev_frame["pose_landmarks"],
                            frame["pose_landmarks"],
                            "pose",
                            mode=self.diff_mode,
                            diff_type=self.diff_type,
                        )
                    )
                if frame["left_hand_landmarks"]:
                    features["differences"] += (
                        self.diff_estimator.compute_differences(
                            prev_frame["left_hand_landmarks"],
                            frame["left_hand_landmarks"],
                            "hand",
                             mode=self.diff_mode,
                            diff_type=self.diff_type,
                        )
                    )
                if frame["right_hand_landmarks"]:
                    features["differences"] += (
                        self.diff_estimator.compute_differences(
                            prev_frame["right_hand_landmarks"],
                            frame["right_hand_landmarks"],
                            "hand",
                             mode=self.diff_mode,
                            diff_type=self.diff_type,
                        )
                    )

        joined = self.joiner.forward(features)
        all_features.append(joined)

        return torch.stack(all_features)
