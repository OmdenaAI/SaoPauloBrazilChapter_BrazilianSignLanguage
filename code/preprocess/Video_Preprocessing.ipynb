{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 02:26:32.372756: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743269192.544962  176545 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743269192.600484  176545 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-30 02:26:33.012095: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from video_analyzer import VideoAnalyzer\n",
    "from preprocessor import Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = \"28032025\"\n",
    "path_to_root = \"/home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(os.path.join(\n",
    "    path_to_root,\n",
    "    \"data\",\n",
    "    \"raw\",\n",
    "    \"combined\",\n",
    "    \"target_dataset_video_metadata.csv\"\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, metadata_row in metadata.iterrows():\n",
    "    analyzer = VideoAnalyzer(\n",
    "        metadata_row,\n",
    "        timestamp,\n",
    "        path_to_root,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    motion_data = analyzer.motion_detect()\n",
    "    motion_result = analyzer.motion_analyze()\n",
    "\n",
    "    pose_data = analyzer.pose_detect()\n",
    "    pose_result = analyzer.pose_analyze()\n",
    "\n",
    "    analyzer.save_analysis_info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_processing_params(analysis_info):\n",
    "    start_frame = analysis_info[\"motion_analysis\"][\"start_frame\"]\n",
    "    end_frame = analysis_info[\"motion_analysis\"][\"end_frame\"]\n",
    "\n",
    "    # horizontal offset\n",
    "    shoulders_median = analysis_info[\"pose_analysis\"][\"horizontal_offsets\"][\"shoulders\"][\"median\"]\n",
    "    face_median = analysis_info[\"pose_analysis\"][\"horizontal_offsets\"][\"face\"][\"median\"]\n",
    "\n",
    "    shoulders_reference = 0.5\n",
    "    face_reference = 0.5\n",
    "\n",
    "    shoulders_offset = shoulders_reference - shoulders_median\n",
    "    face_offset = face_reference - face_median\n",
    "\n",
    "    shoulders_weight = 0.7\n",
    "    face_weight = 0.3\n",
    "    horizontal_offset = shoulders_weight * shoulders_offset + face_weight * face_offset\n",
    "\n",
    "    # Measurements from the video\n",
    "    ## Horizontal\n",
    "    shoulder_width = analysis_info[\"pose_analysis\"][\"landmark_measurements\"][\"shoulder_width\"][\"mean\"]\n",
    "    face_width = analysis_info[\"pose_analysis\"][\"landmark_measurements\"][\"face_width\"][\"mean\"]\n",
    "    ## Vertical\n",
    "    face_height = analysis_info[\"pose_analysis\"][\"landmark_measurements\"][\"face_height\"][\"mean\"]\n",
    "    chin_to_shoulders = analysis_info[\"pose_analysis\"][\"landmark_measurements\"][\"chin_to_shoulders\"][\"median\"]\n",
    "\n",
    "    # Reference values to scale to\n",
    "    ## Horizontal\n",
    "    reference_shoulder_width = 0.3\n",
    "    reference_face_width = 0.15\n",
    "    ## Vertical\n",
    "    reference_face_height = 0.2\n",
    "    reference_chin_to_shoulders = 0.15\n",
    "\n",
    "    # Scale Factors\n",
    "    ## Horizontal\n",
    "    shoulder_width_weight = 0.7\n",
    "    face_width_weight = 0.3\n",
    "    x_scale_factor = shoulder_width_weight * reference_shoulder_width / shoulder_width + face_width_weight * reference_face_width / face_width\n",
    "    ## Vertical\n",
    "    face_height_weight = 0.7\n",
    "    chin_to_shoulders_weight = 0.3\n",
    "    y_scale_factor = face_height_weight * reference_face_height / face_height + chin_to_shoulders_weight * reference_chin_to_shoulders / chin_to_shoulders\n",
    "\n",
    "\n",
    "    # Measured\n",
    "    shoulders_median = analysis_info[\"pose_analysis\"][\"vertical_offsets\"][\"shoulders\"][\"median\"]\n",
    "    face_median = analysis_info[\"pose_analysis\"][\"vertical_offsets\"][\"face\"][\"median\"]\n",
    "    # Reference\n",
    "    reference_shoulders = 0.5\n",
    "    reference_face = 0.25\n",
    "\n",
    "    shoulders_offset = reference_shoulders - shoulders_median\n",
    "    face_offset = reference_face - face_median\n",
    "\n",
    "    # Weighted Average\n",
    "    shoulders_weight = 0.6\n",
    "    face_weight = 0.4\n",
    "    vertical_offset = shoulders_weight * shoulders_offset + face_weight * face_offset\n",
    "\n",
    "    target_duration = 3\n",
    "\n",
    "    params_dict = {\n",
    "        \"start_frame\": start_frame,\n",
    "        \"end_frame\": end_frame,\n",
    "        \"horizontal_offset\": horizontal_offset,\n",
    "        \"vertical_offset\": vertical_offset,\n",
    "        \"x_scale_factor\": x_scale_factor,\n",
    "        \"y_scale_factor\": y_scale_factor,\n",
    "        \"target_duration\": target_duration,\n",
    "    }\n",
    "\n",
    "    return params_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized Preprocessor for ajudar_ne_1.mp4\n",
      "Naming this preprocessing version: v1\n",
      "Preprocessing video: /home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/data/raw/combined/videos/ajudar_ne_1.mp4\n",
      "Loaded 44 frames from video\n",
      "Trimmed video from 44 frames to 32 frames\n",
      "Frame range: 7 to 38\n",
      "Horizontally aligned frames with offset 0.019842283427715303, shifted 5 pixels right\n",
      "Filled empty space with edge colors from the original frame\n",
      "Scaled frames with factors: x=0.9782713052799648, y=0.8576274074905624\n",
      "Using edge colors to fill any empty space from scaling\n",
      "Vertically aligned frames with offset -0.02808350026607513, shifted 5 pixels up\n",
      "Filled empty space with edge colors from the original frame\n",
      "Saved interim processed video to /home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/data/interim/Videos/ajudar_ne_1_processed.mp4\n",
      "Padded frames from 32 to 36 frames\n",
      "Added 2 frames at the start and 2 at the end\n",
      "Saved video metadata to /home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/data/preprocessed/Videos/v1/individual_metadata/ajudar_ne_1.json\n",
      "Saved preprocessed video to /home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/data/preprocessed/Videos/v1/videos/ajudar_ne_1.mp4\n",
      "Updated video metadata CSV at /home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/data/preprocessed/Videos/v1/video_metadata.csv\n",
      "Preprocessing landmarks: /home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/data/interim/RawPoseLandmarks/versionA/ajudar_ne_1.npy\n",
      "Loaded landmarks with shape: (44,)\n",
      "Trimmed landmarks from 44 frames to 32 frames\n",
      "Frame range: 7 to 38\n",
      "Horizontally aligned landmarks with offset 0.019842283427715303, shifted 0.020 right\n",
      "Scaled landmarks with factors: x=0.9782713052799648, y=0.8576274074905624\n",
      "Vertically aligned landmarks with offset -0.02808350026607513, shifted 0.028 up\n",
      "Padding landmarks from 32 to 36 frames\n",
      "Adding 2 frames at the start and 2 at the end\n",
      "Saved landmarks metadata to /home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/data/preprocessed/Landmarks/v1/individual_metadata/ajudar_ne_1.json\n",
      "Saved preprocessed landmarks to /home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/data/preprocessed/Landmarks/v1/landmarks/ajudar_ne_1.npy\n",
      "Updated landmarks metadata CSV at /home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/data/preprocessed/Landmarks/v1/landmarks_metadata.csv\n",
      "Initialized Preprocessor for ajudar_sb_2.mp4\n",
      "Naming this preprocessing version: v1\n",
      "Preprocessing video: /home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/data/raw/combined/videos/ajudar_sb_2.mp4\n",
      "Loaded 79 frames from video\n",
      "Trimmed video from 79 frames to 64 frames\n",
      "Frame range: 8 to 71\n",
      "Horizontally aligned frames with offset 0.0034888207912445067, shifted 4 pixels right\n",
      "Filled empty space with edge colors from the original frame\n",
      "Scaled frames with factors: x=1.5647706098056886, y=1.2308604879523808\n",
      "Using edge colors to fill any empty space from scaling\n",
      "Vertically aligned frames with offset -0.04008085131645203, shifted 29 pixels up\n",
      "Filled empty space with edge colors from the original frame\n",
      "Saved interim processed video to /home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/data/interim/Videos/ajudar_sb_2_processed.mp4\n",
      "Padded frames from 64 to 89 frames\n",
      "Added 12 frames at the start and 13 at the end\n",
      "Saved video metadata to /home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/data/preprocessed/Videos/v1/individual_metadata/ajudar_sb_2.json\n",
      "Saved preprocessed video to /home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/data/preprocessed/Videos/v1/videos/ajudar_sb_2.mp4\n",
      "Updated video metadata CSV at /home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/data/preprocessed/Videos/v1/video_metadata.csv\n",
      "Preprocessing landmarks: /home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/data/interim/RawPoseLandmarks/versionA/ajudar_sb_2.npy\n",
      "Loaded landmarks with shape: (79,)\n",
      "Trimmed landmarks from 79 frames to 64 frames\n",
      "Frame range: 8 to 71\n",
      "Horizontally aligned landmarks with offset 0.0034888207912445067, shifted 0.003 right\n",
      "Scaled landmarks with factors: x=1.5647706098056886, y=1.2308604879523808\n",
      "Vertically aligned landmarks with offset -0.04008085131645203, shifted 0.040 up\n",
      "Padding landmarks from 64 to 89 frames\n",
      "Adding 12 frames at the start and 13 at the end\n",
      "Saved landmarks metadata to /home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/data/preprocessed/Landmarks/v1/individual_metadata/ajudar_sb_2.json\n",
      "Saved preprocessed landmarks to /home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/data/preprocessed/Landmarks/v1/landmarks/ajudar_sb_2.npy\n",
      "Updated landmarks metadata CSV at /home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/data/preprocessed/Landmarks/v1/landmarks_metadata.csv\n",
      "Initialized Preprocessor for ajudar_uf_3.mp4\n",
      "Naming this preprocessing version: v1\n",
      "Preprocessing video: /home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/data/raw/combined/videos/ajudar_uf_3.mp4\n",
      "Loaded 115 frames from video\n",
      "Trimmed video from 115 frames to 81 frames\n",
      "Frame range: 25 to 105\n",
      "Horizontally aligned frames with offset 0.008004866540431976, shifted 4 pixels right\n",
      "Filled empty space with edge colors from the original frame\n",
      "Scaled frames with factors: x=1.5400851267150046, y=1.1177284061246384\n",
      "Using edge colors to fill any empty space from scaling\n",
      "Vertically aligned frames with offset -0.1032309889793396, shifted 28 pixels up\n",
      "Filled empty space with edge colors from the original frame\n",
      "Saved interim processed video to /home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/data/interim/Videos/ajudar_uf_3_processed.mp4\n",
      "Padded frames from 81 to 89 frames\n",
      "Added 4 frames at the start and 4 at the end\n",
      "Saved video metadata to /home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/data/preprocessed/Videos/v1/individual_metadata/ajudar_uf_3.json\n",
      "Saved preprocessed video to /home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/data/preprocessed/Videos/v1/videos/ajudar_uf_3.mp4\n",
      "Updated video metadata CSV at /home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/data/preprocessed/Videos/v1/video_metadata.csv\n",
      "Preprocessing landmarks: /home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/data/interim/RawPoseLandmarks/versionA/ajudar_uf_3.npy\n",
      "Loaded landmarks with shape: (115,)\n",
      "Trimmed landmarks from 115 frames to 81 frames\n",
      "Frame range: 25 to 105\n",
      "Horizontally aligned landmarks with offset 0.008004866540431976, shifted 0.008 right\n",
      "Scaled landmarks with factors: x=1.5400851267150046, y=1.1177284061246384\n",
      "Vertically aligned landmarks with offset -0.1032309889793396, shifted 0.103 up\n",
      "Padding landmarks from 81 to 89 frames\n",
      "Adding 4 frames at the start and 4 at the end\n",
      "Saved landmarks metadata to /home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/data/preprocessed/Landmarks/v1/individual_metadata/ajudar_uf_3.json\n",
      "Saved preprocessed landmarks to /home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/data/preprocessed/Landmarks/v1/landmarks/ajudar_uf_3.npy\n",
      "Updated landmarks metadata CSV at /home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/data/preprocessed/Landmarks/v1/landmarks_metadata.csv\n",
      "Initialized Preprocessor for ajudar_vl_4.mp4\n",
      "Naming this preprocessing version: v1\n",
      "Preprocessing video: /home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/data/raw/combined/videos/ajudar_vl_4.mp4\n",
      "Loaded 141 frames from video\n",
      "Trimmed video from 141 frames to 127 frames\n",
      "Frame range: 12 to 138\n",
      "Horizontally aligned frames with offset -0.0031692758202552795, shifted 6 pixels left\n",
      "Filled empty space with edge colors from the original frame\n",
      "Scaled frames with factors: x=1.5193405591701112, y=1.1318082937513019\n",
      "Using edge colors to fill any empty space from scaling\n",
      "Vertically aligned frames with offset 0.036253660917282104, shifted 39 pixels down\n",
      "Filled empty space with edge colors from the original frame\n",
      "Saved interim processed video to /home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/data/interim/Videos/ajudar_vl_4_processed.mp4\n",
      "No padding needed, current frame count 127 >= target 89\n",
      "Saved video metadata to /home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/data/preprocessed/Videos/v1/individual_metadata/ajudar_vl_4.json\n",
      "Saved preprocessed video to /home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/data/preprocessed/Videos/v1/videos/ajudar_vl_4.mp4\n",
      "Updated video metadata CSV at /home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/data/preprocessed/Videos/v1/video_metadata.csv\n",
      "Preprocessing landmarks: /home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/data/interim/RawPoseLandmarks/versionA/ajudar_vl_4.npy\n",
      "Loaded landmarks with shape: (141,)\n",
      "Trimmed landmarks from 141 frames to 127 frames\n",
      "Frame range: 12 to 138\n",
      "Horizontally aligned landmarks with offset -0.0031692758202552795, shifted 0.003 left\n",
      "Scaled landmarks with factors: x=1.5193405591701112, y=1.1318082937513019\n",
      "Vertically aligned landmarks with offset 0.036253660917282104, shifted 0.036 down\n",
      "No padding needed, current frame count 127 >= target 89\n",
      "Saved landmarks metadata to /home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/data/preprocessed/Landmarks/v1/individual_metadata/ajudar_vl_4.json\n",
      "Saved preprocessed landmarks to /home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/data/preprocessed/Landmarks/v1/landmarks/ajudar_vl_4.npy\n",
      "Updated landmarks metadata CSV at /home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/data/preprocessed/Landmarks/v1/landmarks_metadata.csv\n",
      "Initialized Preprocessor for ajudar_vl_5.mp4\n",
      "Naming this preprocessing version: v1\n",
      "Preprocessing video: /home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/data/raw/combined/videos/ajudar_vl_5.mp4\n",
      "Loaded 289 frames from video\n",
      "Trimmed video from 289 frames to 284 frames\n",
      "Frame range: 4 to 287\n",
      "Horizontally aligned frames with offset 0.0009644493460655211, shifted 2 pixels right\n",
      "Filled empty space with edge colors from the original frame\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for i, metadata_row in metadata.iterrows():\n",
    "    with open(os.path.join(\n",
    "        path_to_root, \n",
    "        \"data\", \n",
    "        \"interim\", \n",
    "        \"Analysis\", \n",
    "        timestamp, \n",
    "        \"individual_json\", \n",
    "        metadata_row[\"filename\"].split(\".\")[0] + \"_analysis_info.json\"\n",
    "        )) as f:\n",
    "        analysis_info = json.load(f)\n",
    "    \n",
    "    preprocessing_params = get_processing_params(analysis_info)\n",
    "\n",
    "    preprocessor = Preprocessor(\n",
    "        metadata_row,\n",
    "        preprocessing_params,\n",
    "        path_to_root,\n",
    "    )\n",
    "\n",
    "    preprocessor.preprocess_video()\n",
    "    preprocessor.preprocess_landmarks()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
