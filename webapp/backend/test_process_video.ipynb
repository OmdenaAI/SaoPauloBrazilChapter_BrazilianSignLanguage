{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-12 11:00:14.476991: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749693614.660421   14359 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749693614.745496   14359 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-12 11:00:15.226902: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from process_video_ben import process_video\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>filename_accented</th>\n",
       "      <th>label</th>\n",
       "      <th>label_accented</th>\n",
       "      <th>accented</th>\n",
       "      <th>data_source</th>\n",
       "      <th>original_fps</th>\n",
       "      <th>original_frame_count</th>\n",
       "      <th>original_duration_sec</th>\n",
       "      <th>start_frame</th>\n",
       "      <th>end_frame</th>\n",
       "      <th>processed_frame_count</th>\n",
       "      <th>processed_duration_sec</th>\n",
       "      <th>preprocess_version</th>\n",
       "      <th>face_width</th>\n",
       "      <th>shoulders_width</th>\n",
       "      <th>face_midpoint_to_shoulders_height</th>\n",
       "      <th>left_hand_interpolated_none_frames</th>\n",
       "      <th>right_hand_interpolated_none_frames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ajudar_ne_1.mp4</td>\n",
       "      <td>ajudar_ne_1.mp4</td>\n",
       "      <td>ajudar</td>\n",
       "      <td>ajudar</td>\n",
       "      <td>False</td>\n",
       "      <td>ne</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>44</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>7</td>\n",
       "      <td>36</td>\n",
       "      <td>30</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>v4</td>\n",
       "      <td>0.147576</td>\n",
       "      <td>0.333421</td>\n",
       "      <td>0.292776</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ajudar_sb_2.mp4</td>\n",
       "      <td>ajudar_sb_2.mp4</td>\n",
       "      <td>ajudar</td>\n",
       "      <td>ajudar</td>\n",
       "      <td>False</td>\n",
       "      <td>sb</td>\n",
       "      <td>29.97003</td>\n",
       "      <td>79</td>\n",
       "      <td>2.635967</td>\n",
       "      <td>6</td>\n",
       "      <td>66</td>\n",
       "      <td>61</td>\n",
       "      <td>2.035367</td>\n",
       "      <td>v4</td>\n",
       "      <td>0.086359</td>\n",
       "      <td>0.206200</td>\n",
       "      <td>0.216821</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ajudar_uf_3.mp4</td>\n",
       "      <td>ajudar_uf_3.mp4</td>\n",
       "      <td>ajudar</td>\n",
       "      <td>ajudar</td>\n",
       "      <td>False</td>\n",
       "      <td>uf</td>\n",
       "      <td>29.97003</td>\n",
       "      <td>115</td>\n",
       "      <td>3.837167</td>\n",
       "      <td>24</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>2.202200</td>\n",
       "      <td>v4</td>\n",
       "      <td>0.090604</td>\n",
       "      <td>0.205890</td>\n",
       "      <td>0.222293</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ajudar_vl_4.mp4</td>\n",
       "      <td>ajudar_vl_4.mp4</td>\n",
       "      <td>ajudar</td>\n",
       "      <td>ajudar</td>\n",
       "      <td>False</td>\n",
       "      <td>vl</td>\n",
       "      <td>29.97003</td>\n",
       "      <td>141</td>\n",
       "      <td>4.704700</td>\n",
       "      <td>11</td>\n",
       "      <td>126</td>\n",
       "      <td>116</td>\n",
       "      <td>3.870533</td>\n",
       "      <td>v4</td>\n",
       "      <td>0.100236</td>\n",
       "      <td>0.210215</td>\n",
       "      <td>0.240169</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ajudar_vl_5.mp4</td>\n",
       "      <td>ajudar_vl_5.mp4</td>\n",
       "      <td>ajudar</td>\n",
       "      <td>ajudar</td>\n",
       "      <td>False</td>\n",
       "      <td>vl</td>\n",
       "      <td>29.97000</td>\n",
       "      <td>108</td>\n",
       "      <td>3.603604</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>107</td>\n",
       "      <td>3.570237</td>\n",
       "      <td>v4</td>\n",
       "      <td>0.114839</td>\n",
       "      <td>0.243479</td>\n",
       "      <td>0.246769</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          filename filename_accented   label label_accented  accented  \\\n",
       "0  ajudar_ne_1.mp4   ajudar_ne_1.mp4  ajudar         ajudar     False   \n",
       "1  ajudar_sb_2.mp4   ajudar_sb_2.mp4  ajudar         ajudar     False   \n",
       "2  ajudar_uf_3.mp4   ajudar_uf_3.mp4  ajudar         ajudar     False   \n",
       "3  ajudar_vl_4.mp4   ajudar_vl_4.mp4  ajudar         ajudar     False   \n",
       "4  ajudar_vl_5.mp4   ajudar_vl_5.mp4  ajudar         ajudar     False   \n",
       "\n",
       "  data_source  original_fps  original_frame_count  original_duration_sec  \\\n",
       "0          ne      12.00000                    44               3.666667   \n",
       "1          sb      29.97003                    79               2.635967   \n",
       "2          uf      29.97003                   115               3.837167   \n",
       "3          vl      29.97003                   141               4.704700   \n",
       "4          vl      29.97000                   108               3.603604   \n",
       "\n",
       "   start_frame  end_frame  processed_frame_count  processed_duration_sec  \\\n",
       "0            7         36                     30                2.500000   \n",
       "1            6         66                     61                2.035367   \n",
       "2           24         89                     66                2.202200   \n",
       "3           11        126                    116                3.870533   \n",
       "4            0        106                    107                3.570237   \n",
       "\n",
       "  preprocess_version  face_width  shoulders_width  \\\n",
       "0                 v4    0.147576         0.333421   \n",
       "1                 v4    0.086359         0.206200   \n",
       "2                 v4    0.090604         0.205890   \n",
       "3                 v4    0.100236         0.210215   \n",
       "4                 v4    0.114839         0.243479   \n",
       "\n",
       "   face_midpoint_to_shoulders_height  left_hand_interpolated_none_frames  \\\n",
       "0                           0.292776                                   7   \n",
       "1                           0.216821                                   0   \n",
       "2                           0.222293                                   0   \n",
       "3                           0.240169                                  25   \n",
       "4                           0.246769                                  13   \n",
       "\n",
       "   right_hand_interpolated_none_frames  \n",
       "0                                    6  \n",
       "1                                    0  \n",
       "2                                    0  \n",
       "3                                    9  \n",
       "4                                   12  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.read_csv(\"/home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/data/preprocessed/landmarks_metadata_v4.csv\")\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42     cabeça_ne_1.mp4\n",
       "43     cabeça_sb_2.mp4\n",
       "44     cabeça_uf_3.mp4\n",
       "45     cabeça_vl_4.mp4\n",
       "46     cabeça_vl_5.mp4\n",
       "            ...       \n",
       "145    vagina_sb_2.mp4\n",
       "146    vagina_uf_3.mp4\n",
       "147    vagina_vl_4.mp4\n",
       "148    vagina_vl_5.mp4\n",
       "149    vagina_vl_6.mp4\n",
       "Name: filename_accented, Length: 108, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata[\"filename_accented\"][42:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = {}\n",
    "\n",
    "for fn in metadata[\"filename_accented\"]:\n",
    "    prediction, probs_str, label_encoding = process_video(fn)\n",
    "    output_dict[fn] = {\n",
    "        \"prediction\": prediction,\n",
    "        \"probs_str\": probs_str,\n",
    "        \"label_encoding\": label_encoding\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metadata = pd.read_csv(\"/home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/modelling/metadata/landmarks_metadata_v4_training.csv\")\n",
    "train_metadata = model_metadata[model_metadata[\"dataset_split\"] == \"train\"]\n",
    "test_metadata = model_metadata[model_metadata[\"dataset_split\"] == \"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ajudar_ne_1.mp4 15 ajudar 0.999\n",
      "ajudar_sb_2.mp4 15 ajudar 1.0\n",
      "ajudar_uf_3.mp4 15 ajudar 0.999\n",
      "ajudar_vl_4.mp4 15 ajudar 0.999\n",
      "ajudar_vl_6.mp4 15 ajudar 0.999\n",
      "animal_ne_1.mp4 21 animal 1.0\n",
      "animal_sb_2.mp4 21 animal 0.999\n",
      "animal_uf_3.mp4 21 animal 1.0\n",
      "animal_vl_5.mp4 21 animal 0.999\n",
      "animal_vl_6.mp4 21 animal 0.999\n",
      "aniversário_ne_1.mp4 3 aniversário 1.0\n",
      "aniversário_sb_2.mp4 3 aniversário 1.0\n",
      "aniversário_vl_4.mp4 3 aniversário 1.0\n",
      "aniversário_vl_5.mp4 3 aniversário 1.0\n",
      "aniversário_vl_6.mp4 3 aniversário 1.0\n",
      "ano_ne_1.mp4 6 ano 1.0\n",
      "ano_uf_3.mp4 6 ano 1.0\n",
      "ano_vl_4.mp4 6 ano 1.0\n",
      "ano_vl_5.mp4 6 ano 1.0\n",
      "ano_vl_6.mp4 6 ano 1.0\n",
      "banana_sb_2.mp4 9 banana 1.0\n",
      "banana_uf_3.mp4 9 banana 1.0\n",
      "banana_vl_4.mp4 9 banana 1.0\n",
      "banana_vl_5.mp4 9 banana 1.0\n",
      "banana_vl_6.mp4 9 banana 0.999\n",
      "banheiro_ne_1.mp4 18 banheiro 0.999\n",
      "banheiro_sb_2.mp4 18 banheiro 1.0\n",
      "banheiro_uf_3.mp4 18 banheiro 1.0\n",
      "banheiro_vl_4.mp4 18 banheiro 1.0\n",
      "banheiro_vl_5.mp4 18 banheiro 1.0\n",
      "bebê_ne_1.mp4 2 bebê 1.0\n",
      "bebê_sb_2.mp4 2 bebê 1.0\n",
      "bebê_uf_3.mp4 2 bebê 1.0\n",
      "bebê_vl_4.mp4 2 bebê 1.0\n",
      "bebê_vl_6.mp4 2 bebê 1.0\n",
      "cabeça_ne_1.mp4 1 cabeça 0.999\n",
      "cabeça_sb_2.mp4 1 cabeça 0.999\n",
      "cabeça_uf_3.mp4 1 cabeça 0.999\n",
      "cabeça_vl_5.mp4 1 cabeça 0.999\n",
      "cabeça_vl_6.mp4 1 cabeça 0.999\n",
      "café_ne_1.mp4 20 café 0.999\n",
      "café_sb_2.mp4 20 café 0.999\n",
      "café_vl_4.mp4 20 café 0.999\n",
      "café_vl_5.mp4 20 café 0.999\n",
      "café_vl_6.mp4 20 café 1.0\n",
      "carne_ne_1.mp4 16 carne 0.999\n",
      "carne_uf_3.mp4 16 carne 1.0\n",
      "carne_vl_4.mp4 16 carne 1.0\n",
      "carne_vl_5.mp4 16 carne 0.999\n",
      "carne_vl_6.mp4 16 carne 1.0\n",
      "casa_sb_2.mp4 14 casa 0.999\n",
      "casa_uf_3.mp4 14 casa 0.999\n",
      "casa_vl_4.mp4 14 casa 0.999\n",
      "casa_vl_5.mp4 14 casa 0.999\n",
      "casa_vl_6.mp4 14 casa 0.999\n",
      "cebola_ne_1.mp4 24 cebola 0.999\n",
      "cebola_sb_2.mp4 24 cebola 1.0\n",
      "cebola_uf_3.mp4 24 cebola 0.995\n",
      "cebola_vl_4.mp4 24 cebola 1.0\n",
      "cebola_vl_5.mp4 24 cebola 0.999\n",
      "comer_ne_1.mp4 11 comer 0.999\n",
      "comer_sb_2.mp4 11 comer 1.0\n",
      "comer_uf_3.mp4 11 comer 1.0\n",
      "comer_vl_4.mp4 11 comer 1.0\n",
      "comer_vl_6.mp4 11 comer 0.999\n",
      "cortar_ne_1.mp4 7 cortar 0.999\n",
      "cortar_sb_2.mp4 7 cortar 0.999\n",
      "cortar_uf_3.mp4 7 cortar 0.999\n",
      "cortar_vl_5.mp4 7 cortar 0.999\n",
      "cortar_vl_6.mp4 7 cortar 0.999\n",
      "crescer_ne_1.mp4 5 crescer 0.999\n",
      "crescer_sb_2.mp4 5 crescer 1.0\n",
      "crescer_vl_4.mp4 5 crescer 0.999\n",
      "crescer_vl_5.mp4 5 crescer 0.999\n",
      "crescer_vl_6.mp4 5 crescer 1.0\n",
      "família_ne_1.mp4 19 família 0.999\n",
      "família_uf_3.mp4 19 família 0.999\n",
      "família_vl_4.mp4 19 família 0.999\n",
      "família_vl_5.mp4 19 família 0.999\n",
      "família_vl_6.mp4 19 família 0.999\n",
      "filho_sb_2.mp4 23 filho 0.999\n",
      "filho_uf_3.mp4 23 filho 0.999\n",
      "filho_vl_4.mp4 23 filho 0.999\n",
      "filho_vl_5.mp4 23 filho 0.999\n",
      "filho_vl_6.mp4 23 filho 0.999\n",
      "garganta_ne_1.mp4 8 garganta 0.999\n",
      "garganta_sb_2.mp4 8 garganta 0.999\n",
      "garganta_uf_3.mp4 8 garganta 1.0\n",
      "garganta_vl_4.mp4 8 garganta 1.0\n",
      "garganta_vl_5.mp4 8 garganta 1.0\n",
      "homem_ne_1.mp4 0 homem 0.999\n",
      "homem_sb_2.mp4 0 homem 1.0\n",
      "homem_uf_3.mp4 0 homem 1.0\n",
      "homem_vl_4.mp4 0 homem 1.0\n",
      "homem_vl_6.mp4 0 homem 0.999\n",
      "jovem_ne_1.mp4 4 jovem 1.0\n",
      "jovem_sb_2.mp4 4 jovem 1.0\n",
      "jovem_uf_3.mp4 4 jovem 1.0\n",
      "jovem_vl_5.mp4 4 jovem 1.0\n",
      "jovem_vl_6.mp4 4 jovem 1.0\n",
      "ouvir_ne_1.mp4 10 ouvir 0.999\n",
      "ouvir_sb_2.mp4 10 ouvir 0.999\n",
      "ouvir_vl_4.mp4 10 ouvir 0.999\n",
      "ouvir_vl_5.mp4 10 ouvir 0.999\n",
      "ouvir_vl_6.mp4 10 ouvir 1.0\n",
      "pai_ne_1.mp4 22 pai 0.999\n",
      "pai_uf_3.mp4 22 pai 1.0\n",
      "pai_vl_4.mp4 22 pai 0.998\n",
      "pai_vl_5.mp4 22 pai 1.0\n",
      "pai_vl_6.mp4 22 pai 1.0\n",
      "sopa_sb_2.mp4 13 sopa 1.0\n",
      "sopa_uf_3.mp4 13 sopa 1.0\n",
      "sopa_vl_4.mp4 13 sopa 1.0\n",
      "sopa_vl_5.mp4 13 sopa 1.0\n",
      "sopa_vl_6.mp4 13 sopa 0.999\n",
      "sorvete_ne_1.mp4 17 sorvete 0.999\n",
      "sorvete_sb_2.mp4 17 sorvete 0.999\n",
      "sorvete_uf_3.mp4 17 sorvete 0.999\n",
      "sorvete_vl_4.mp4 17 sorvete 1.0\n",
      "sorvete_vl_5.mp4 17 sorvete 1.0\n",
      "vagina_ne_1.mp4 12 vagina 1.0\n",
      "vagina_sb_2.mp4 12 vagina 1.0\n",
      "vagina_uf_3.mp4 12 vagina 1.0\n",
      "vagina_vl_4.mp4 12 vagina 1.0\n",
      "vagina_vl_6.mp4 12 vagina 1.0\n"
     ]
    }
   ],
   "source": [
    "output_folder = \"/home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/webapp/backend/data/output/\"\n",
    "train_eval = []\n",
    "for fn in train_metadata[\"filename_accented\"]:\n",
    "    fn_txt = fn.replace(\".mp4\", \".txt\")\n",
    "    fn_txt_fp = os.path.join(output_folder, fn_txt)\n",
    "    with open(fn_txt_fp, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    pred = lines[1]\n",
    "    pred_class = int(pred.split(\":\")[0].split(\" \")[1])\n",
    "    pred_label = pred.split(\":\")[1].strip()\n",
    "    max_prob = np.max([float(num) for num in [line.split(' ')[-1] for line in lines[2].split(\",\")][:-1]])\n",
    "    print(fn, pred_class, pred_label, max_prob)\n",
    "    if fn.split('_')[0] == pred_label:\n",
    "        train_eval.append(1)\n",
    "    else:\n",
    "        train_eval.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ajudar_vl_5.mp4 6 ano 0.871\n",
      "animal_vl_4.mp4 21 animal 0.933\n",
      "aniversário_uf_3.mp4 3 aniversário 0.999\n",
      "ano_sb_2.mp4 6 ano 1.0\n",
      "banana_ne_1.mp4 9 banana 0.987\n",
      "banheiro_vl_6.mp4 18 banheiro 0.989\n",
      "bebê_vl_5.mp4 2 bebê 0.998\n",
      "cabeça_vl_4.mp4 1 cabeça 0.997\n",
      "café_uf_3.mp4 16 carne 0.523\n",
      "carne_sb_2.mp4 15 ajudar 0.931\n",
      "casa_ne_1.mp4 19 família 0.998\n",
      "cebola_vl_6.mp4 17 sorvete 0.574\n",
      "comer_vl_5.mp4 8 garganta 0.964\n",
      "cortar_vl_4.mp4 23 filho 0.596\n",
      "crescer_uf_3.mp4 5 crescer 0.991\n",
      "família_sb_2.mp4 19 família 0.999\n",
      "filho_ne_1.mp4 23 filho 0.948\n",
      "garganta_vl_6.mp4 0 homem 0.999\n",
      "homem_vl_5.mp4 8 garganta 0.942\n",
      "jovem_vl_4.mp4 4 jovem 0.999\n",
      "ouvir_uf_3.mp4 10 ouvir 0.999\n",
      "pai_sb_2.mp4 22 pai 0.8\n",
      "sopa_ne_1.mp4 21 animal 0.447\n",
      "sorvete_vl_6.mp4 17 sorvete 1.0\n",
      "vagina_vl_5.mp4 12 vagina 1.0\n"
     ]
    }
   ],
   "source": [
    "output_folder = \"/home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/webapp/backend/data/output/\"\n",
    "test_eval = []\n",
    "for fn in test_metadata[\"filename_accented\"]:\n",
    "    fn_txt = fn.replace(\".mp4\", \".txt\")\n",
    "    fn_txt_fp = os.path.join(output_folder, fn_txt)\n",
    "    with open(fn_txt_fp, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    pred = lines[1]\n",
    "    pred_class = int(pred.split(\":\")[0].split(\" \")[1])\n",
    "    pred_label = pred.split(\":\")[1].strip()\n",
    "    max_prob = np.max([float(num) for num in [line.split(' ')[-1] for line in lines[2].split(\",\")][:-1]])\n",
    "    print(fn, pred_class, pred_label, max_prob)\n",
    "    if fn.split('_')[0] == pred_label:\n",
    "        test_eval.append(1)\n",
    "    else:\n",
    "        test_eval.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 100.00% (n=125)\n",
      "Test Accuracy: 60.00% (n=25)\n"
     ]
    }
   ],
   "source": [
    "print(f'Train Accuracy: {np.mean(train_eval)*100:.2f}% (n={len(train_eval)})')\n",
    "print(f'Test Accuracy: {np.mean(test_eval)*100:.2f}% (n={len(test_eval)})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Backend Preprocessing Matches Development/Training Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def landmark_to_array(landmarks):\n",
    "    lm_arrays = {\n",
    "        \"left_hand_landmarks\":[], \n",
    "        \"right_hand_landmarks\":[], \n",
    "        \"pose_landmarks\":[],\n",
    "        \"face_landmarks\":[]\n",
    "    }\n",
    "    for frame in landmarks:\n",
    "        for key in lm_arrays.keys():\n",
    "            lm_array = [[lm.x, lm.y, lm.z] for lm in frame[f\"{key}\"].landmark]\n",
    "            lm_arrays[key].append(lm_array)\n",
    "\n",
    "    return lm_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_check_dict = {}\n",
    "\n",
    "orig_npy_folder = \"/home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/data/preprocessed/landmarks/v4\"\n",
    "new_npy_folder = \"/home/ben/projects/SaoPauloBrazilChapter_BrazilianSignLanguage/webapp/backend/data/preprocessed/landmarks/v0\"\n",
    "\n",
    "for i, row in metadata.iterrows():\n",
    "    fn = row[\"filename\"]\n",
    "    fn_a = row[\"filename_accented\"]\n",
    "    fn = fn.replace(\".mp4\", \".npy\")\n",
    "    fn_a = fn_a.replace(\".mp4\", \".npy\")\n",
    "    orig_npy_fp = os.path.join(orig_npy_folder, fn)\n",
    "    new_npy_fp = os.path.join(new_npy_folder, fn_a)\n",
    "    orig_npy = np.load(orig_npy_fp, allow_pickle=True)\n",
    "    new_npy = np.load(new_npy_fp, allow_pickle=True)\n",
    "    orig_lm_arrays = landmark_to_array(orig_npy)\n",
    "    new_lm_arrays = landmark_to_array(new_npy)\n",
    "    check_dict = {\n",
    "    \"left_hand_landmarks\":True, \n",
    "    \"right_hand_landmarks\":True, \n",
    "    \"pose_landmarks\":True,\n",
    "    \"face_landmarks\":True\n",
    "    }\n",
    "    for key in check_dict.keys():\n",
    "        if not np.array_equal(orig_lm_arrays[key], new_lm_arrays[key]):\n",
    "            check_dict[key] = False\n",
    "    np_check_dict[fn] = check_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_df = pd.DataFrame(np_check_dict).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_hand_landmarks</th>\n",
       "      <th>right_hand_landmarks</th>\n",
       "      <th>pose_landmarks</th>\n",
       "      <th>face_landmarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [left_hand_landmarks, right_hand_landmarks, pose_landmarks, face_landmarks]\n",
       "Index: []"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_df[check_df[\"left_hand_landmarks\"] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_hand_landmarks</th>\n",
       "      <th>right_hand_landmarks</th>\n",
       "      <th>pose_landmarks</th>\n",
       "      <th>face_landmarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [left_hand_landmarks, right_hand_landmarks, pose_landmarks, face_landmarks]\n",
       "Index: []"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_df[check_df[\"right_hand_landmarks\"] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_hand_landmarks</th>\n",
       "      <th>right_hand_landmarks</th>\n",
       "      <th>pose_landmarks</th>\n",
       "      <th>face_landmarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [left_hand_landmarks, right_hand_landmarks, pose_landmarks, face_landmarks]\n",
       "Index: []"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_df[check_df[\"pose_landmarks\"] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_hand_landmarks</th>\n",
       "      <th>right_hand_landmarks</th>\n",
       "      <th>pose_landmarks</th>\n",
       "      <th>face_landmarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [left_hand_landmarks, right_hand_landmarks, pose_landmarks, face_landmarks]\n",
       "Index: []"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_df[check_df[\"face_landmarks\"] == False]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
